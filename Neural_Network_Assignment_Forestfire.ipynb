{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Network_Assignment_Forestfire.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6VYQFv2NyEp"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "_Sr0kqwbOM5u",
        "outputId": "e3b198ad-9dc7-4dbd-8a11-c580f64af19e"
      },
      "source": [
        "data = pd.read_csv('/content/forestfires.csv')\n",
        "data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>area</th>\n",
              "      <th>dayfri</th>\n",
              "      <th>daymon</th>\n",
              "      <th>daysat</th>\n",
              "      <th>daysun</th>\n",
              "      <th>daythu</th>\n",
              "      <th>daytue</th>\n",
              "      <th>daywed</th>\n",
              "      <th>monthapr</th>\n",
              "      <th>monthaug</th>\n",
              "      <th>monthdec</th>\n",
              "      <th>monthfeb</th>\n",
              "      <th>monthjan</th>\n",
              "      <th>monthjul</th>\n",
              "      <th>monthjun</th>\n",
              "      <th>monthmar</th>\n",
              "      <th>monthmay</th>\n",
              "      <th>monthnov</th>\n",
              "      <th>monthoct</th>\n",
              "      <th>monthsep</th>\n",
              "      <th>size_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mar</td>\n",
              "      <td>fri</td>\n",
              "      <td>86.2</td>\n",
              "      <td>26.2</td>\n",
              "      <td>94.3</td>\n",
              "      <td>5.1</td>\n",
              "      <td>8.2</td>\n",
              "      <td>51</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>oct</td>\n",
              "      <td>tue</td>\n",
              "      <td>90.6</td>\n",
              "      <td>35.4</td>\n",
              "      <td>669.1</td>\n",
              "      <td>6.7</td>\n",
              "      <td>18.0</td>\n",
              "      <td>33</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>oct</td>\n",
              "      <td>sat</td>\n",
              "      <td>90.6</td>\n",
              "      <td>43.7</td>\n",
              "      <td>686.9</td>\n",
              "      <td>6.7</td>\n",
              "      <td>14.6</td>\n",
              "      <td>33</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mar</td>\n",
              "      <td>fri</td>\n",
              "      <td>91.7</td>\n",
              "      <td>33.3</td>\n",
              "      <td>77.5</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.3</td>\n",
              "      <td>97</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>mar</td>\n",
              "      <td>sun</td>\n",
              "      <td>89.3</td>\n",
              "      <td>51.3</td>\n",
              "      <td>102.2</td>\n",
              "      <td>9.6</td>\n",
              "      <td>11.4</td>\n",
              "      <td>99</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>aug</td>\n",
              "      <td>sun</td>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>27.8</td>\n",
              "      <td>32</td>\n",
              "      <td>2.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.44</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>aug</td>\n",
              "      <td>sun</td>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>21.9</td>\n",
              "      <td>71</td>\n",
              "      <td>5.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>54.29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>aug</td>\n",
              "      <td>sun</td>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>21.2</td>\n",
              "      <td>70</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>aug</td>\n",
              "      <td>sat</td>\n",
              "      <td>94.4</td>\n",
              "      <td>146.0</td>\n",
              "      <td>614.7</td>\n",
              "      <td>11.3</td>\n",
              "      <td>25.6</td>\n",
              "      <td>42</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>nov</td>\n",
              "      <td>tue</td>\n",
              "      <td>79.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>106.7</td>\n",
              "      <td>1.1</td>\n",
              "      <td>11.8</td>\n",
              "      <td>31</td>\n",
              "      <td>4.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>517 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    month  day  FFMC    DMC  ...  monthnov  monthoct  monthsep  size_category\n",
              "0     mar  fri  86.2   26.2  ...         0         0         0          small\n",
              "1     oct  tue  90.6   35.4  ...         0         1         0          small\n",
              "2     oct  sat  90.6   43.7  ...         0         1         0          small\n",
              "3     mar  fri  91.7   33.3  ...         0         0         0          small\n",
              "4     mar  sun  89.3   51.3  ...         0         0         0          small\n",
              "..    ...  ...   ...    ...  ...       ...       ...       ...            ...\n",
              "512   aug  sun  81.6   56.7  ...         0         0         0          large\n",
              "513   aug  sun  81.6   56.7  ...         0         0         0          large\n",
              "514   aug  sun  81.6   56.7  ...         0         0         0          large\n",
              "515   aug  sat  94.4  146.0  ...         0         0         0          small\n",
              "516   nov  tue  79.5    3.0  ...         1         0         0          small\n",
              "\n",
              "[517 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MJ0LVnNORJs",
        "outputId": "aed4378e-6193-4ef4-d30c-5698a97a6327"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 517 entries, 0 to 516\n",
            "Data columns (total 31 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   month          517 non-null    object \n",
            " 1   day            517 non-null    object \n",
            " 2   FFMC           517 non-null    float64\n",
            " 3   DMC            517 non-null    float64\n",
            " 4   DC             517 non-null    float64\n",
            " 5   ISI            517 non-null    float64\n",
            " 6   temp           517 non-null    float64\n",
            " 7   RH             517 non-null    int64  \n",
            " 8   wind           517 non-null    float64\n",
            " 9   rain           517 non-null    float64\n",
            " 10  area           517 non-null    float64\n",
            " 11  dayfri         517 non-null    int64  \n",
            " 12  daymon         517 non-null    int64  \n",
            " 13  daysat         517 non-null    int64  \n",
            " 14  daysun         517 non-null    int64  \n",
            " 15  daythu         517 non-null    int64  \n",
            " 16  daytue         517 non-null    int64  \n",
            " 17  daywed         517 non-null    int64  \n",
            " 18  monthapr       517 non-null    int64  \n",
            " 19  monthaug       517 non-null    int64  \n",
            " 20  monthdec       517 non-null    int64  \n",
            " 21  monthfeb       517 non-null    int64  \n",
            " 22  monthjan       517 non-null    int64  \n",
            " 23  monthjul       517 non-null    int64  \n",
            " 24  monthjun       517 non-null    int64  \n",
            " 25  monthmar       517 non-null    int64  \n",
            " 26  monthmay       517 non-null    int64  \n",
            " 27  monthnov       517 non-null    int64  \n",
            " 28  monthoct       517 non-null    int64  \n",
            " 29  monthsep       517 non-null    int64  \n",
            " 30  size_category  517 non-null    object \n",
            "dtypes: float64(8), int64(20), object(3)\n",
            "memory usage: 125.3+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVapoSM2OhNZ"
      },
      "source": [
        "#Since number of columns are more, lets use PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yf9LZDMLOYcM",
        "outputId": "4154b172-7d1b-4b3c-b499-60d9ad4821e6"
      },
      "source": [
        "df1 = data.iloc[:,2:30]\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "\n",
        "sc.fit(df1)\n",
        "df_norm = sc.transform(df1)\n",
        "df_norm"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-8.05959472e-01, -1.32332557e+00, -1.83047676e+00, ...,\n",
              "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
              "       [-8.10203395e-03, -1.17954077e+00,  4.88890915e-01, ...,\n",
              "        -4.40225453e-02,  5.78503817e+00, -7.06081245e-01],\n",
              "       [-8.10203395e-03, -1.04982188e+00,  5.60715454e-01, ...,\n",
              "        -4.40225453e-02,  5.78503817e+00, -7.06081245e-01],\n",
              "       ...,\n",
              "       [-1.64008316e+00, -8.46647711e-01,  4.74768113e-01, ...,\n",
              "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
              "       [ 6.80956663e-01,  5.49002541e-01,  2.69382214e-01, ...,\n",
              "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
              "       [-2.02087875e+00, -1.68591332e+00, -1.78044169e+00, ...,\n",
              "         2.27156334e+01, -1.72859706e-01, -7.06081245e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fs8X_1ciO8nL",
        "outputId": "4299cac9-32e3-4d0d-9e50-a23a29c7b423"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components = 28)\n",
        "pca_values = pca.fit_transform(df_norm)\n",
        "pca_values"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3.76670947e+00, -1.32025451e+00, -8.43971398e-01, ...,\n",
              "        -6.53345819e-02, -6.05082538e-15, -1.58743875e-16],\n",
              "       [ 3.90786263e-01,  8.31061522e-01, -1.10136513e+00, ...,\n",
              "         3.42618601e-02, -2.67236885e-15, -6.92610536e-16],\n",
              "       [ 6.90415596e-01,  1.17774562e+00, -1.22199841e+00, ...,\n",
              "         2.63235187e-02,  5.92028990e-15,  8.36530871e-16],\n",
              "       ...,\n",
              "       [ 9.21634000e-01, -2.64543072e-01,  2.71921606e+00, ...,\n",
              "        -2.97865814e-01, -6.98934052e-16,  4.03200598e-18],\n",
              "       [-1.62054896e+00, -9.78838231e-01,  3.31987355e-01, ...,\n",
              "         3.91949863e-02,  5.57925976e-16, -3.39227990e-17],\n",
              "       [ 4.07590654e+00, -3.67440726e-01, -2.47151775e-01, ...,\n",
              "        -2.50420726e-02,  6.17289277e-17, -8.31075187e-17]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMW0ZlqNPW41",
        "outputId": "8da8f433-50f3-416d-ea97-4a63262024f5"
      },
      "source": [
        "var = pca.explained_variance_ratio_\n",
        "var"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.35522746e-01, 6.85788793e-02, 6.23572652e-02, 5.32713255e-02,\n",
              "       4.75942360e-02, 4.68009902e-02, 4.37490015e-02, 4.28025164e-02,\n",
              "       4.08875728e-02, 4.01633268e-02, 3.92926854e-02, 3.83232321e-02,\n",
              "       3.64221503e-02, 3.63217289e-02, 3.57856782e-02, 3.50087806e-02,\n",
              "       3.35447704e-02, 3.24777366e-02, 3.04490902e-02, 3.00246758e-02,\n",
              "       2.37167400e-02, 2.08329788e-02, 1.18357869e-02, 8.88449559e-03,\n",
              "       4.55347471e-03, 7.98135931e-04, 2.67271490e-32, 3.42850975e-33])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNM3EYpQPe6a",
        "outputId": "d85e14a1-b3d0-40a0-ff9c-e52447c3461c"
      },
      "source": [
        "var1 = np.cumsum(np.round(var, decimals = 4)*100)\n",
        "var1"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([13.55, 20.41, 26.65, 31.98, 36.74, 41.42, 45.79, 50.07, 54.16,\n",
              "       58.18, 62.11, 65.94, 69.58, 73.21, 76.79, 80.29, 83.64, 86.89,\n",
              "       89.93, 92.93, 95.3 , 97.38, 98.56, 99.45, 99.91, 99.99, 99.99,\n",
              "       99.99])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "45CJkg6cPnZE",
        "outputId": "e45fb991-e047-479e-9750-b3f7e9eadb26"
      },
      "source": [
        "plt.figure(figsize=(12,4))\n",
        "plt.plot(var1, color= 'red');"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "FjUSCfJpPwqW",
        "outputId": "10524331-7b3b-4d65-86a9-ad4b17ec772c"
      },
      "source": [
        "finalDf = pd.concat([pd.DataFrame(pca_values[:,0:24], columns = ['pc1','pc2','pc3','pc4','pc5','pc6','pc7',\n",
        "                                                             'pc8','pc9','pc10','pc11','pc12','pc13','pc14',\n",
        "                                                             'pc15','pc16','pc17','pc18','pc19','pc20','pc21',\n",
        "                                                             'pc22','pc23','pc24']),\n",
        "                     data[['size_category']]], axis =1)\n",
        "finalDf.size_category.replace(('large', 'small'),(1,0), inplace=True)\n",
        "finalDf"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pc1</th>\n",
              "      <th>pc2</th>\n",
              "      <th>pc3</th>\n",
              "      <th>pc4</th>\n",
              "      <th>pc5</th>\n",
              "      <th>pc6</th>\n",
              "      <th>pc7</th>\n",
              "      <th>pc8</th>\n",
              "      <th>pc9</th>\n",
              "      <th>pc10</th>\n",
              "      <th>pc11</th>\n",
              "      <th>pc12</th>\n",
              "      <th>pc13</th>\n",
              "      <th>pc14</th>\n",
              "      <th>pc15</th>\n",
              "      <th>pc16</th>\n",
              "      <th>pc17</th>\n",
              "      <th>pc18</th>\n",
              "      <th>pc19</th>\n",
              "      <th>pc20</th>\n",
              "      <th>pc21</th>\n",
              "      <th>pc22</th>\n",
              "      <th>pc23</th>\n",
              "      <th>pc24</th>\n",
              "      <th>size_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.766709</td>\n",
              "      <td>-1.320255</td>\n",
              "      <td>-0.843971</td>\n",
              "      <td>-1.994738</td>\n",
              "      <td>-1.453359</td>\n",
              "      <td>0.693985</td>\n",
              "      <td>0.308104</td>\n",
              "      <td>-0.019764</td>\n",
              "      <td>0.010161</td>\n",
              "      <td>-0.437314</td>\n",
              "      <td>-0.536738</td>\n",
              "      <td>1.234550</td>\n",
              "      <td>0.276198</td>\n",
              "      <td>-0.671216</td>\n",
              "      <td>-0.529599</td>\n",
              "      <td>-0.197543</td>\n",
              "      <td>-0.021839</td>\n",
              "      <td>0.688958</td>\n",
              "      <td>0.563603</td>\n",
              "      <td>-0.439596</td>\n",
              "      <td>-0.926619</td>\n",
              "      <td>-0.405425</td>\n",
              "      <td>-0.118719</td>\n",
              "      <td>-0.017933</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.390786</td>\n",
              "      <td>0.831062</td>\n",
              "      <td>-1.101365</td>\n",
              "      <td>1.400671</td>\n",
              "      <td>2.869388</td>\n",
              "      <td>0.965898</td>\n",
              "      <td>-2.795574</td>\n",
              "      <td>0.041095</td>\n",
              "      <td>-0.548879</td>\n",
              "      <td>0.104500</td>\n",
              "      <td>-2.876498</td>\n",
              "      <td>-0.568255</td>\n",
              "      <td>2.095225</td>\n",
              "      <td>1.417634</td>\n",
              "      <td>-0.879983</td>\n",
              "      <td>-2.503167</td>\n",
              "      <td>0.499649</td>\n",
              "      <td>0.563706</td>\n",
              "      <td>-0.703319</td>\n",
              "      <td>-1.535718</td>\n",
              "      <td>-0.892995</td>\n",
              "      <td>0.836590</td>\n",
              "      <td>0.204975</td>\n",
              "      <td>0.290771</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.690416</td>\n",
              "      <td>1.177746</td>\n",
              "      <td>-1.221998</td>\n",
              "      <td>2.442038</td>\n",
              "      <td>1.090630</td>\n",
              "      <td>0.390801</td>\n",
              "      <td>-1.586675</td>\n",
              "      <td>-2.159336</td>\n",
              "      <td>-0.090580</td>\n",
              "      <td>0.260888</td>\n",
              "      <td>-3.236229</td>\n",
              "      <td>-0.601439</td>\n",
              "      <td>1.998004</td>\n",
              "      <td>1.477351</td>\n",
              "      <td>-0.946682</td>\n",
              "      <td>-2.545144</td>\n",
              "      <td>-0.658411</td>\n",
              "      <td>-0.423618</td>\n",
              "      <td>0.860550</td>\n",
              "      <td>-1.195230</td>\n",
              "      <td>-0.297870</td>\n",
              "      <td>0.743648</td>\n",
              "      <td>0.081757</td>\n",
              "      <td>0.345915</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.359951</td>\n",
              "      <td>-1.161443</td>\n",
              "      <td>0.385728</td>\n",
              "      <td>-2.118328</td>\n",
              "      <td>-1.949601</td>\n",
              "      <td>1.027664</td>\n",
              "      <td>-0.179422</td>\n",
              "      <td>-0.250227</td>\n",
              "      <td>-0.620329</td>\n",
              "      <td>-1.343189</td>\n",
              "      <td>-0.145846</td>\n",
              "      <td>1.019492</td>\n",
              "      <td>0.576990</td>\n",
              "      <td>-0.752744</td>\n",
              "      <td>0.349346</td>\n",
              "      <td>-0.040887</td>\n",
              "      <td>0.017843</td>\n",
              "      <td>0.332572</td>\n",
              "      <td>1.164745</td>\n",
              "      <td>-1.632741</td>\n",
              "      <td>-0.817618</td>\n",
              "      <td>1.523710</td>\n",
              "      <td>-0.342302</td>\n",
              "      <td>-0.378420</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.974329</td>\n",
              "      <td>-0.842626</td>\n",
              "      <td>1.327788</td>\n",
              "      <td>0.038086</td>\n",
              "      <td>-1.124763</td>\n",
              "      <td>-0.574676</td>\n",
              "      <td>-0.777155</td>\n",
              "      <td>0.303635</td>\n",
              "      <td>0.861126</td>\n",
              "      <td>-2.024719</td>\n",
              "      <td>-0.467108</td>\n",
              "      <td>1.131879</td>\n",
              "      <td>-0.137990</td>\n",
              "      <td>-0.823316</td>\n",
              "      <td>0.402298</td>\n",
              "      <td>0.844431</td>\n",
              "      <td>1.014944</td>\n",
              "      <td>-0.618231</td>\n",
              "      <td>0.822853</td>\n",
              "      <td>-1.794109</td>\n",
              "      <td>-0.723371</td>\n",
              "      <td>2.020419</td>\n",
              "      <td>-0.545591</td>\n",
              "      <td>0.161735</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>-0.087560</td>\n",
              "      <td>0.153964</td>\n",
              "      <td>1.241810</td>\n",
              "      <td>1.536581</td>\n",
              "      <td>0.372425</td>\n",
              "      <td>-1.133422</td>\n",
              "      <td>-0.362287</td>\n",
              "      <td>0.766946</td>\n",
              "      <td>0.818745</td>\n",
              "      <td>-0.289632</td>\n",
              "      <td>-0.933909</td>\n",
              "      <td>0.161275</td>\n",
              "      <td>-0.398215</td>\n",
              "      <td>0.197490</td>\n",
              "      <td>-0.801640</td>\n",
              "      <td>0.300522</td>\n",
              "      <td>0.513876</td>\n",
              "      <td>0.539642</td>\n",
              "      <td>-0.052958</td>\n",
              "      <td>1.898628</td>\n",
              "      <td>-1.441786</td>\n",
              "      <td>-0.821192</td>\n",
              "      <td>-1.205707</td>\n",
              "      <td>-0.698666</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>0.794366</td>\n",
              "      <td>-0.083966</td>\n",
              "      <td>2.670485</td>\n",
              "      <td>0.284995</td>\n",
              "      <td>0.223323</td>\n",
              "      <td>-0.904232</td>\n",
              "      <td>-0.014849</td>\n",
              "      <td>0.107226</td>\n",
              "      <td>1.340049</td>\n",
              "      <td>-0.147246</td>\n",
              "      <td>-0.652051</td>\n",
              "      <td>-0.132893</td>\n",
              "      <td>-0.518732</td>\n",
              "      <td>0.162358</td>\n",
              "      <td>-0.274733</td>\n",
              "      <td>0.342367</td>\n",
              "      <td>0.485571</td>\n",
              "      <td>0.580150</td>\n",
              "      <td>0.384984</td>\n",
              "      <td>0.086251</td>\n",
              "      <td>-0.970693</td>\n",
              "      <td>-1.353365</td>\n",
              "      <td>-1.254890</td>\n",
              "      <td>-1.212175</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>0.921634</td>\n",
              "      <td>-0.264543</td>\n",
              "      <td>2.719216</td>\n",
              "      <td>-0.019643</td>\n",
              "      <td>0.242195</td>\n",
              "      <td>-0.966939</td>\n",
              "      <td>-0.118080</td>\n",
              "      <td>0.123010</td>\n",
              "      <td>1.290364</td>\n",
              "      <td>-0.177553</td>\n",
              "      <td>-0.657663</td>\n",
              "      <td>-0.083060</td>\n",
              "      <td>-0.285899</td>\n",
              "      <td>0.062647</td>\n",
              "      <td>-0.494765</td>\n",
              "      <td>0.332816</td>\n",
              "      <td>0.344047</td>\n",
              "      <td>0.122409</td>\n",
              "      <td>0.313948</td>\n",
              "      <td>0.211157</td>\n",
              "      <td>-0.777731</td>\n",
              "      <td>-1.736711</td>\n",
              "      <td>-1.154127</td>\n",
              "      <td>-1.230040</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>-1.620549</td>\n",
              "      <td>-0.978838</td>\n",
              "      <td>0.331987</td>\n",
              "      <td>1.256638</td>\n",
              "      <td>-0.408164</td>\n",
              "      <td>0.735698</td>\n",
              "      <td>0.815510</td>\n",
              "      <td>-1.398344</td>\n",
              "      <td>0.076379</td>\n",
              "      <td>-0.005814</td>\n",
              "      <td>-0.503898</td>\n",
              "      <td>0.174276</td>\n",
              "      <td>-0.163149</td>\n",
              "      <td>0.246912</td>\n",
              "      <td>-0.147679</td>\n",
              "      <td>-0.011739</td>\n",
              "      <td>-1.035533</td>\n",
              "      <td>-0.774382</td>\n",
              "      <td>-0.216315</td>\n",
              "      <td>0.515791</td>\n",
              "      <td>0.080575</td>\n",
              "      <td>-0.055548</td>\n",
              "      <td>-0.067502</td>\n",
              "      <td>-0.311027</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>4.075907</td>\n",
              "      <td>-0.367441</td>\n",
              "      <td>-0.247152</td>\n",
              "      <td>0.979966</td>\n",
              "      <td>6.792273</td>\n",
              "      <td>5.943666</td>\n",
              "      <td>-1.639583</td>\n",
              "      <td>8.121827</td>\n",
              "      <td>-0.627980</td>\n",
              "      <td>4.953722</td>\n",
              "      <td>-1.411962</td>\n",
              "      <td>2.986327</td>\n",
              "      <td>-2.734589</td>\n",
              "      <td>6.584205</td>\n",
              "      <td>-6.010301</td>\n",
              "      <td>10.467443</td>\n",
              "      <td>-7.333036</td>\n",
              "      <td>0.377340</td>\n",
              "      <td>8.870354</td>\n",
              "      <td>-1.074288</td>\n",
              "      <td>2.382433</td>\n",
              "      <td>1.042850</td>\n",
              "      <td>0.296436</td>\n",
              "      <td>0.125099</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>517 rows × 25 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          pc1       pc2       pc3  ...      pc23      pc24  size_category\n",
              "0    3.766709 -1.320255 -0.843971  ... -0.118719 -0.017933              0\n",
              "1    0.390786  0.831062 -1.101365  ...  0.204975  0.290771              0\n",
              "2    0.690416  1.177746 -1.221998  ...  0.081757  0.345915              0\n",
              "3    3.359951 -1.161443  0.385728  ... -0.342302 -0.378420              0\n",
              "4    2.974329 -0.842626  1.327788  ... -0.545591  0.161735              0\n",
              "..        ...       ...       ...  ...       ...       ...            ...\n",
              "512 -0.087560  0.153964  1.241810  ... -1.205707 -0.698666              1\n",
              "513  0.794366 -0.083966  2.670485  ... -1.254890 -1.212175              1\n",
              "514  0.921634 -0.264543  2.719216  ... -1.154127 -1.230040              1\n",
              "515 -1.620549 -0.978838  0.331987  ... -0.067502 -0.311027              0\n",
              "516  4.075907 -0.367441 -0.247152  ...  0.296436  0.125099              0\n",
              "\n",
              "[517 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXqADFA-Qowb",
        "outputId": "3ed6a485-7edc-4965-dc57-618149892dd2"
      },
      "source": [
        "array = finalDf.values\n",
        "X = array[:, 0:24]\n",
        "Y = array[:,24]\n",
        "\n",
        "X.reshape(-1, 1)\n",
        "Y.reshape(-1, 1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I0ncbWdRBMz"
      },
      "source": [
        "#Iteration 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTE2m3BZQ7WZ",
        "outputId": "2fa33797-3e74-422b-d690-686076c6ad0c"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=24, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "#Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, Y, validation_split=0.3, epochs=150, batch_size=10)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "37/37 [==============================] - 12s 13ms/step - loss: 1.0749 - accuracy: 0.2712 - val_loss: 0.8536 - val_accuracy: 0.3846\n",
            "Epoch 2/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.8610 - accuracy: 0.3249 - val_loss: 0.7465 - val_accuracy: 0.4167\n",
            "Epoch 3/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.7341 - accuracy: 0.4760 - val_loss: 0.6955 - val_accuracy: 0.5321\n",
            "Epoch 4/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.6450 - accuracy: 0.6392 - val_loss: 0.6666 - val_accuracy: 0.6410\n",
            "Epoch 5/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.6100 - accuracy: 0.6834 - val_loss: 0.6504 - val_accuracy: 0.6731\n",
            "Epoch 6/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.7774 - val_loss: 0.6417 - val_accuracy: 0.6987\n",
            "Epoch 7/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.7614 - val_loss: 0.6399 - val_accuracy: 0.6859\n",
            "Epoch 8/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.8057 - val_loss: 0.6374 - val_accuracy: 0.6987\n",
            "Epoch 9/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.8311 - val_loss: 0.6383 - val_accuracy: 0.7051\n",
            "Epoch 10/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.8049 - val_loss: 0.6370 - val_accuracy: 0.7051\n",
            "Epoch 11/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.8256 - val_loss: 0.6343 - val_accuracy: 0.7051\n",
            "Epoch 12/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.8096 - val_loss: 0.6364 - val_accuracy: 0.7051\n",
            "Epoch 13/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.7843 - val_loss: 0.6379 - val_accuracy: 0.7051\n",
            "Epoch 14/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.8278 - val_loss: 0.6403 - val_accuracy: 0.7051\n",
            "Epoch 15/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.8021 - val_loss: 0.6396 - val_accuracy: 0.6923\n",
            "Epoch 16/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.8175 - val_loss: 0.6415 - val_accuracy: 0.6859\n",
            "Epoch 17/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7955 - val_loss: 0.6426 - val_accuracy: 0.6859\n",
            "Epoch 18/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.8018 - val_loss: 0.6428 - val_accuracy: 0.6987\n",
            "Epoch 19/150\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4102 - accuracy: 0.8250 - val_loss: 0.6445 - val_accuracy: 0.6859\n",
            "Epoch 20/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8680 - val_loss: 0.6480 - val_accuracy: 0.6859\n",
            "Epoch 21/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8284 - val_loss: 0.6459 - val_accuracy: 0.6795\n",
            "Epoch 22/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8437 - val_loss: 0.6454 - val_accuracy: 0.6923\n",
            "Epoch 23/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8460 - val_loss: 0.6486 - val_accuracy: 0.6923\n",
            "Epoch 24/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8561 - val_loss: 0.6519 - val_accuracy: 0.6859\n",
            "Epoch 25/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3789 - accuracy: 0.8236 - val_loss: 0.6524 - val_accuracy: 0.6859\n",
            "Epoch 26/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8444 - val_loss: 0.6547 - val_accuracy: 0.6987\n",
            "Epoch 27/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8386 - val_loss: 0.6538 - val_accuracy: 0.7051\n",
            "Epoch 28/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.8254 - val_loss: 0.6546 - val_accuracy: 0.7115\n",
            "Epoch 29/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3492 - accuracy: 0.8500 - val_loss: 0.6475 - val_accuracy: 0.7051\n",
            "Epoch 30/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3400 - accuracy: 0.8326 - val_loss: 0.6546 - val_accuracy: 0.7051\n",
            "Epoch 31/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8321 - val_loss: 0.6635 - val_accuracy: 0.6987\n",
            "Epoch 32/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.8665 - val_loss: 0.6632 - val_accuracy: 0.7051\n",
            "Epoch 33/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.8631 - val_loss: 0.6684 - val_accuracy: 0.7115\n",
            "Epoch 34/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8470 - val_loss: 0.6778 - val_accuracy: 0.7115\n",
            "Epoch 35/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8676 - val_loss: 0.6771 - val_accuracy: 0.7051\n",
            "Epoch 36/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3185 - accuracy: 0.8519 - val_loss: 0.6751 - val_accuracy: 0.7179\n",
            "Epoch 37/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3212 - accuracy: 0.8716 - val_loss: 0.6766 - val_accuracy: 0.7179\n",
            "Epoch 38/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.8285 - val_loss: 0.6783 - val_accuracy: 0.7179\n",
            "Epoch 39/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3331 - accuracy: 0.8664 - val_loss: 0.6838 - val_accuracy: 0.7308\n",
            "Epoch 40/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8530 - val_loss: 0.6742 - val_accuracy: 0.7372\n",
            "Epoch 41/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.8724 - val_loss: 0.6858 - val_accuracy: 0.7244\n",
            "Epoch 42/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8530 - val_loss: 0.6879 - val_accuracy: 0.7115\n",
            "Epoch 43/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2632 - accuracy: 0.8885 - val_loss: 0.6938 - val_accuracy: 0.7115\n",
            "Epoch 44/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3053 - accuracy: 0.8732 - val_loss: 0.6971 - val_accuracy: 0.7115\n",
            "Epoch 45/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2842 - accuracy: 0.8770 - val_loss: 0.7017 - val_accuracy: 0.7179\n",
            "Epoch 46/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3156 - accuracy: 0.8467 - val_loss: 0.7049 - val_accuracy: 0.7115\n",
            "Epoch 47/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2670 - accuracy: 0.8908 - val_loss: 0.7057 - val_accuracy: 0.7115\n",
            "Epoch 48/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8557 - val_loss: 0.7122 - val_accuracy: 0.7115\n",
            "Epoch 49/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2683 - accuracy: 0.8853 - val_loss: 0.7147 - val_accuracy: 0.7115\n",
            "Epoch 50/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2608 - accuracy: 0.8918 - val_loss: 0.7111 - val_accuracy: 0.7244\n",
            "Epoch 51/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2718 - accuracy: 0.8874 - val_loss: 0.7185 - val_accuracy: 0.7179\n",
            "Epoch 52/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2730 - accuracy: 0.8770 - val_loss: 0.7150 - val_accuracy: 0.7179\n",
            "Epoch 53/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2486 - accuracy: 0.9089 - val_loss: 0.7173 - val_accuracy: 0.7179\n",
            "Epoch 54/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2342 - accuracy: 0.9245 - val_loss: 0.7213 - val_accuracy: 0.7179\n",
            "Epoch 55/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2579 - accuracy: 0.9005 - val_loss: 0.7237 - val_accuracy: 0.7179\n",
            "Epoch 56/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2107 - accuracy: 0.9228 - val_loss: 0.7275 - val_accuracy: 0.7179\n",
            "Epoch 57/150\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.2145 - accuracy: 0.9167 - val_loss: 0.7264 - val_accuracy: 0.7179\n",
            "Epoch 58/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2241 - accuracy: 0.9343 - val_loss: 0.7276 - val_accuracy: 0.7115\n",
            "Epoch 59/150\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.2165 - accuracy: 0.9188 - val_loss: 0.7274 - val_accuracy: 0.7115\n",
            "Epoch 60/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2132 - accuracy: 0.9363 - val_loss: 0.7354 - val_accuracy: 0.7179\n",
            "Epoch 61/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.9246 - val_loss: 0.7337 - val_accuracy: 0.7244\n",
            "Epoch 62/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2288 - accuracy: 0.9298 - val_loss: 0.7357 - val_accuracy: 0.7179\n",
            "Epoch 63/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2240 - accuracy: 0.9216 - val_loss: 0.7353 - val_accuracy: 0.7244\n",
            "Epoch 64/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.8879 - val_loss: 0.7354 - val_accuracy: 0.7244\n",
            "Epoch 65/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2358 - accuracy: 0.8961 - val_loss: 0.7405 - val_accuracy: 0.7244\n",
            "Epoch 66/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2383 - accuracy: 0.8964 - val_loss: 0.7276 - val_accuracy: 0.7308\n",
            "Epoch 67/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2062 - accuracy: 0.9256 - val_loss: 0.7357 - val_accuracy: 0.7308\n",
            "Epoch 68/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2133 - accuracy: 0.9252 - val_loss: 0.7395 - val_accuracy: 0.7244\n",
            "Epoch 69/150\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.2153 - accuracy: 0.9253 - val_loss: 0.7334 - val_accuracy: 0.7372\n",
            "Epoch 70/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1755 - accuracy: 0.9393 - val_loss: 0.7403 - val_accuracy: 0.7372\n",
            "Epoch 71/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1995 - accuracy: 0.9299 - val_loss: 0.7381 - val_accuracy: 0.7372\n",
            "Epoch 72/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2351 - accuracy: 0.9004 - val_loss: 0.7338 - val_accuracy: 0.7436\n",
            "Epoch 73/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2562 - accuracy: 0.8934 - val_loss: 0.7332 - val_accuracy: 0.7372\n",
            "Epoch 74/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2104 - accuracy: 0.9123 - val_loss: 0.7348 - val_accuracy: 0.7372\n",
            "Epoch 75/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1808 - accuracy: 0.9244 - val_loss: 0.7318 - val_accuracy: 0.7372\n",
            "Epoch 76/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1755 - accuracy: 0.9382 - val_loss: 0.7294 - val_accuracy: 0.7372\n",
            "Epoch 77/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1936 - accuracy: 0.9297 - val_loss: 0.7273 - val_accuracy: 0.7372\n",
            "Epoch 78/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1741 - accuracy: 0.9393 - val_loss: 0.7299 - val_accuracy: 0.7372\n",
            "Epoch 79/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1503 - accuracy: 0.9457 - val_loss: 0.7250 - val_accuracy: 0.7372\n",
            "Epoch 80/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1890 - accuracy: 0.9213 - val_loss: 0.7194 - val_accuracy: 0.7564\n",
            "Epoch 81/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.9313 - val_loss: 0.7232 - val_accuracy: 0.7500\n",
            "Epoch 82/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.9204 - val_loss: 0.7248 - val_accuracy: 0.7500\n",
            "Epoch 83/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1622 - accuracy: 0.9502 - val_loss: 0.7251 - val_accuracy: 0.7564\n",
            "Epoch 84/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1800 - accuracy: 0.9292 - val_loss: 0.7270 - val_accuracy: 0.7564\n",
            "Epoch 85/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1737 - accuracy: 0.9353 - val_loss: 0.7240 - val_accuracy: 0.7628\n",
            "Epoch 86/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1627 - accuracy: 0.9360 - val_loss: 0.7311 - val_accuracy: 0.7564\n",
            "Epoch 87/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1694 - accuracy: 0.9279 - val_loss: 0.7235 - val_accuracy: 0.7628\n",
            "Epoch 88/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1633 - accuracy: 0.9363 - val_loss: 0.7250 - val_accuracy: 0.7692\n",
            "Epoch 89/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1461 - accuracy: 0.9566 - val_loss: 0.7275 - val_accuracy: 0.7628\n",
            "Epoch 90/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1365 - accuracy: 0.9529 - val_loss: 0.7276 - val_accuracy: 0.7628\n",
            "Epoch 91/150\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.1398 - accuracy: 0.9459 - val_loss: 0.7288 - val_accuracy: 0.7628\n",
            "Epoch 92/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1332 - accuracy: 0.9431 - val_loss: 0.7310 - val_accuracy: 0.7692\n",
            "Epoch 93/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1562 - accuracy: 0.9367 - val_loss: 0.7331 - val_accuracy: 0.7628\n",
            "Epoch 94/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1517 - accuracy: 0.9437 - val_loss: 0.7307 - val_accuracy: 0.7628\n",
            "Epoch 95/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1408 - accuracy: 0.9471 - val_loss: 0.7346 - val_accuracy: 0.7628\n",
            "Epoch 96/150\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.1411 - accuracy: 0.9354 - val_loss: 0.7358 - val_accuracy: 0.7692\n",
            "Epoch 97/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1562 - accuracy: 0.9333 - val_loss: 0.7343 - val_accuracy: 0.7692\n",
            "Epoch 98/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1418 - accuracy: 0.9469 - val_loss: 0.7313 - val_accuracy: 0.7692\n",
            "Epoch 99/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1274 - accuracy: 0.9641 - val_loss: 0.7360 - val_accuracy: 0.7692\n",
            "Epoch 100/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1434 - accuracy: 0.9498 - val_loss: 0.7349 - val_accuracy: 0.7692\n",
            "Epoch 101/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1354 - accuracy: 0.9689 - val_loss: 0.7328 - val_accuracy: 0.7564\n",
            "Epoch 102/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1390 - accuracy: 0.9578 - val_loss: 0.7361 - val_accuracy: 0.7756\n",
            "Epoch 103/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1325 - accuracy: 0.9591 - val_loss: 0.7376 - val_accuracy: 0.7756\n",
            "Epoch 104/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1356 - accuracy: 0.9476 - val_loss: 0.7400 - val_accuracy: 0.7756\n",
            "Epoch 105/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1184 - accuracy: 0.9621 - val_loss: 0.7367 - val_accuracy: 0.7756\n",
            "Epoch 106/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1299 - accuracy: 0.9550 - val_loss: 0.7408 - val_accuracy: 0.7756\n",
            "Epoch 107/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1427 - accuracy: 0.9467 - val_loss: 0.7335 - val_accuracy: 0.7756\n",
            "Epoch 108/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1165 - accuracy: 0.9611 - val_loss: 0.7455 - val_accuracy: 0.7756\n",
            "Epoch 109/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1233 - accuracy: 0.9622 - val_loss: 0.7387 - val_accuracy: 0.7692\n",
            "Epoch 110/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1078 - accuracy: 0.9708 - val_loss: 0.7405 - val_accuracy: 0.7692\n",
            "Epoch 111/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1126 - accuracy: 0.9596 - val_loss: 0.7368 - val_accuracy: 0.7821\n",
            "Epoch 112/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1003 - accuracy: 0.9719 - val_loss: 0.7469 - val_accuracy: 0.7821\n",
            "Epoch 113/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1157 - accuracy: 0.9698 - val_loss: 0.7389 - val_accuracy: 0.7885\n",
            "Epoch 114/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0957 - accuracy: 0.9701 - val_loss: 0.7421 - val_accuracy: 0.7885\n",
            "Epoch 115/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1036 - accuracy: 0.9676 - val_loss: 0.7477 - val_accuracy: 0.7885\n",
            "Epoch 116/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1091 - accuracy: 0.9725 - val_loss: 0.7542 - val_accuracy: 0.7885\n",
            "Epoch 117/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1133 - accuracy: 0.9468 - val_loss: 0.7569 - val_accuracy: 0.7821\n",
            "Epoch 118/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1149 - accuracy: 0.9555 - val_loss: 0.7515 - val_accuracy: 0.7949\n",
            "Epoch 119/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1122 - accuracy: 0.9615 - val_loss: 0.7530 - val_accuracy: 0.7821\n",
            "Epoch 120/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1067 - accuracy: 0.9662 - val_loss: 0.7503 - val_accuracy: 0.7885\n",
            "Epoch 121/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1180 - accuracy: 0.9541 - val_loss: 0.7503 - val_accuracy: 0.7885\n",
            "Epoch 122/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0991 - accuracy: 0.9661 - val_loss: 0.7624 - val_accuracy: 0.7949\n",
            "Epoch 123/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1258 - accuracy: 0.9456 - val_loss: 0.7571 - val_accuracy: 0.7885\n",
            "Epoch 124/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0996 - accuracy: 0.9732 - val_loss: 0.7651 - val_accuracy: 0.7885\n",
            "Epoch 125/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0956 - accuracy: 0.9637 - val_loss: 0.7564 - val_accuracy: 0.8013\n",
            "Epoch 126/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0894 - accuracy: 0.9763 - val_loss: 0.7545 - val_accuracy: 0.8205\n",
            "Epoch 127/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0908 - accuracy: 0.9786 - val_loss: 0.7537 - val_accuracy: 0.8077\n",
            "Epoch 128/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1033 - accuracy: 0.9693 - val_loss: 0.7626 - val_accuracy: 0.8077\n",
            "Epoch 129/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0869 - accuracy: 0.9791 - val_loss: 0.7602 - val_accuracy: 0.8141\n",
            "Epoch 130/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1001 - accuracy: 0.9809 - val_loss: 0.7624 - val_accuracy: 0.8077\n",
            "Epoch 131/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0818 - accuracy: 0.9762 - val_loss: 0.7627 - val_accuracy: 0.8077\n",
            "Epoch 132/150\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0787 - accuracy: 0.9860 - val_loss: 0.7598 - val_accuracy: 0.8077\n",
            "Epoch 133/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0768 - accuracy: 0.9881 - val_loss: 0.7612 - val_accuracy: 0.8141\n",
            "Epoch 134/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0794 - accuracy: 0.9870 - val_loss: 0.7618 - val_accuracy: 0.8077\n",
            "Epoch 135/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0847 - accuracy: 0.9872 - val_loss: 0.7617 - val_accuracy: 0.8205\n",
            "Epoch 136/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0846 - accuracy: 0.9821 - val_loss: 0.7583 - val_accuracy: 0.8205\n",
            "Epoch 137/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0998 - accuracy: 0.9797 - val_loss: 0.7689 - val_accuracy: 0.8205\n",
            "Epoch 138/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0947 - accuracy: 0.9736 - val_loss: 0.7711 - val_accuracy: 0.8141\n",
            "Epoch 139/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0832 - accuracy: 0.9629 - val_loss: 0.7665 - val_accuracy: 0.8205\n",
            "Epoch 140/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0735 - accuracy: 0.9880 - val_loss: 0.7637 - val_accuracy: 0.8333\n",
            "Epoch 141/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0971 - accuracy: 0.9774 - val_loss: 0.7689 - val_accuracy: 0.8333\n",
            "Epoch 142/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0710 - accuracy: 0.9801 - val_loss: 0.7754 - val_accuracy: 0.8269\n",
            "Epoch 143/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0787 - accuracy: 0.9884 - val_loss: 0.7689 - val_accuracy: 0.8205\n",
            "Epoch 144/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0817 - accuracy: 0.9881 - val_loss: 0.7813 - val_accuracy: 0.8205\n",
            "Epoch 145/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0866 - accuracy: 0.9765 - val_loss: 0.7765 - val_accuracy: 0.8269\n",
            "Epoch 146/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0770 - accuracy: 0.9838 - val_loss: 0.7802 - val_accuracy: 0.8397\n",
            "Epoch 147/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0600 - accuracy: 0.9881 - val_loss: 0.7816 - val_accuracy: 0.8269\n",
            "Epoch 148/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.9945 - val_loss: 0.7887 - val_accuracy: 0.8397\n",
            "Epoch 149/150\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0771 - accuracy: 0.9847 - val_loss: 0.7898 - val_accuracy: 0.8397\n",
            "Epoch 150/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.9966 - val_loss: 0.7886 - val_accuracy: 0.8397\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fadf1f5b550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aLObhjzRzSp",
        "outputId": "fbf9b89f-293e-40d8-fb6c-6ad316f5626f"
      },
      "source": [
        "# evaluate the model\n",
        "score = model.evaluate(X,Y)\n",
        "print('%s: %.2f%%' % (model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17/17 [==============================] - 0s 1ms/step - loss: 0.2823 - accuracy: 0.9478\n",
            "accuracy: 94.78%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGRKae2lSVRW"
      },
      "source": [
        "# Iteration 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGgOayJlSJ_4",
        "outputId": "7bda9baa-fea3-4d23-c664-ced57ebe2afb"
      },
      "source": [
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=24, activation='sigmoid'))\n",
        "model.add(Dense(8,activation='sigmoid'))\n",
        "model.add(Dense(1,activation='relu'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, Y, validation_split=0.3, epochs=100, batch_size=15)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "25/25 [==============================] - 1s 11ms/step - loss: 0.5737 - accuracy: 0.7621 - val_loss: 0.6517 - val_accuracy: 0.6731\n",
            "Epoch 2/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5647 - accuracy: 0.7409 - val_loss: 0.6629 - val_accuracy: 0.6731\n",
            "Epoch 3/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7509 - val_loss: 0.6608 - val_accuracy: 0.6731\n",
            "Epoch 4/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5586 - accuracy: 0.7432 - val_loss: 0.6504 - val_accuracy: 0.6731\n",
            "Epoch 5/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.7871 - val_loss: 0.6581 - val_accuracy: 0.6731\n",
            "Epoch 6/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5603 - accuracy: 0.7358 - val_loss: 0.6445 - val_accuracy: 0.6731\n",
            "Epoch 7/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.7761 - val_loss: 0.6498 - val_accuracy: 0.6731\n",
            "Epoch 8/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.7624 - val_loss: 0.6544 - val_accuracy: 0.6731\n",
            "Epoch 9/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7951 - val_loss: 0.6571 - val_accuracy: 0.6731\n",
            "Epoch 10/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.7825 - val_loss: 0.6505 - val_accuracy: 0.6731\n",
            "Epoch 11/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7596 - val_loss: 0.6556 - val_accuracy: 0.6731\n",
            "Epoch 12/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7683 - val_loss: 0.6571 - val_accuracy: 0.6795\n",
            "Epoch 13/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 0.7749 - val_loss: 0.6513 - val_accuracy: 0.6795\n",
            "Epoch 14/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5024 - accuracy: 0.7695 - val_loss: 0.6256 - val_accuracy: 0.6795\n",
            "Epoch 15/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.7529 - val_loss: 0.6342 - val_accuracy: 0.6795\n",
            "Epoch 16/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7847 - val_loss: 0.6625 - val_accuracy: 0.6795\n",
            "Epoch 17/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7689 - val_loss: 0.6453 - val_accuracy: 0.6795\n",
            "Epoch 18/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7785 - val_loss: 0.6395 - val_accuracy: 0.6795\n",
            "Epoch 19/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7478 - val_loss: 0.6673 - val_accuracy: 0.6795\n",
            "Epoch 20/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7730 - val_loss: 0.6877 - val_accuracy: 0.6795\n",
            "Epoch 21/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.7859 - val_loss: 0.6486 - val_accuracy: 0.6859\n",
            "Epoch 22/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4535 - accuracy: 0.8042 - val_loss: 0.7321 - val_accuracy: 0.6859\n",
            "Epoch 23/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.8017 - val_loss: 0.7203 - val_accuracy: 0.6859\n",
            "Epoch 24/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7873 - val_loss: 0.7527 - val_accuracy: 0.6859\n",
            "Epoch 25/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.8003 - val_loss: 0.7406 - val_accuracy: 0.6859\n",
            "Epoch 26/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7957 - val_loss: 0.7250 - val_accuracy: 0.6923\n",
            "Epoch 27/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7894 - val_loss: 0.8955 - val_accuracy: 0.6859\n",
            "Epoch 28/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7905 - val_loss: 0.8950 - val_accuracy: 0.6923\n",
            "Epoch 29/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7917 - val_loss: 0.8909 - val_accuracy: 0.6923\n",
            "Epoch 30/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7906 - val_loss: 0.8866 - val_accuracy: 0.6923\n",
            "Epoch 31/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7934 - val_loss: 0.8914 - val_accuracy: 0.6923\n",
            "Epoch 32/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.8046 - val_loss: 0.8841 - val_accuracy: 0.6923\n",
            "Epoch 33/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7954 - val_loss: 0.8699 - val_accuracy: 0.7051\n",
            "Epoch 34/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8272 - val_loss: 0.9532 - val_accuracy: 0.7051\n",
            "Epoch 35/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7984 - val_loss: 0.8782 - val_accuracy: 0.7051\n",
            "Epoch 36/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8186 - val_loss: 0.9502 - val_accuracy: 0.7051\n",
            "Epoch 37/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.8149 - val_loss: 0.8723 - val_accuracy: 0.7051\n",
            "Epoch 38/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7924 - val_loss: 0.9351 - val_accuracy: 0.7051\n",
            "Epoch 39/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3974 - accuracy: 0.8288 - val_loss: 0.9408 - val_accuracy: 0.7051\n",
            "Epoch 40/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.8004 - val_loss: 0.9354 - val_accuracy: 0.7051\n",
            "Epoch 41/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8013 - val_loss: 0.9389 - val_accuracy: 0.7051\n",
            "Epoch 42/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4123 - accuracy: 0.7832 - val_loss: 0.9338 - val_accuracy: 0.7051\n",
            "Epoch 43/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7806 - val_loss: 0.9251 - val_accuracy: 0.7051\n",
            "Epoch 44/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.7990 - val_loss: 0.9334 - val_accuracy: 0.7051\n",
            "Epoch 45/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8212 - val_loss: 0.9192 - val_accuracy: 0.7051\n",
            "Epoch 46/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8197 - val_loss: 0.9203 - val_accuracy: 0.7051\n",
            "Epoch 47/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3948 - accuracy: 0.8120 - val_loss: 0.9109 - val_accuracy: 0.7051\n",
            "Epoch 48/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7964 - val_loss: 0.9017 - val_accuracy: 0.7179\n",
            "Epoch 49/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.8226 - val_loss: 0.9857 - val_accuracy: 0.7051\n",
            "Epoch 50/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8075 - val_loss: 0.9851 - val_accuracy: 0.7115\n",
            "Epoch 51/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.8089 - val_loss: 0.9826 - val_accuracy: 0.7115\n",
            "Epoch 52/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.3914 - accuracy: 0.7995 - val_loss: 0.9775 - val_accuracy: 0.7244\n",
            "Epoch 53/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.3882 - accuracy: 0.7974 - val_loss: 0.9731 - val_accuracy: 0.7308\n",
            "Epoch 54/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3643 - accuracy: 0.8058 - val_loss: 0.9757 - val_accuracy: 0.7308\n",
            "Epoch 55/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3878 - accuracy: 0.7991 - val_loss: 0.9707 - val_accuracy: 0.7436\n",
            "Epoch 56/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3581 - accuracy: 0.8171 - val_loss: 0.9679 - val_accuracy: 0.7372\n",
            "Epoch 57/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3409 - accuracy: 0.8352 - val_loss: 0.8960 - val_accuracy: 0.7564\n",
            "Epoch 58/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3664 - accuracy: 0.8095 - val_loss: 0.9570 - val_accuracy: 0.7564\n",
            "Epoch 59/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3513 - accuracy: 0.8331 - val_loss: 0.9536 - val_accuracy: 0.7628\n",
            "Epoch 60/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3643 - accuracy: 0.8176 - val_loss: 0.9501 - val_accuracy: 0.7692\n",
            "Epoch 61/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3371 - accuracy: 0.8259 - val_loss: 0.9502 - val_accuracy: 0.7692\n",
            "Epoch 62/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8427 - val_loss: 0.9428 - val_accuracy: 0.7756\n",
            "Epoch 63/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3566 - accuracy: 0.8080 - val_loss: 0.9426 - val_accuracy: 0.7692\n",
            "Epoch 64/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8055 - val_loss: 0.9348 - val_accuracy: 0.7821\n",
            "Epoch 65/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.3446 - accuracy: 0.8173 - val_loss: 0.9323 - val_accuracy: 0.7821\n",
            "Epoch 66/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3552 - accuracy: 0.7980 - val_loss: 0.9260 - val_accuracy: 0.7885\n",
            "Epoch 67/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3451 - accuracy: 0.8118 - val_loss: 0.9237 - val_accuracy: 0.7821\n",
            "Epoch 68/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3318 - accuracy: 0.8161 - val_loss: 0.9195 - val_accuracy: 0.7885\n",
            "Epoch 69/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8119 - val_loss: 0.9170 - val_accuracy: 0.7949\n",
            "Epoch 70/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3212 - accuracy: 0.8270 - val_loss: 0.9153 - val_accuracy: 0.7949\n",
            "Epoch 71/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3193 - accuracy: 0.8351 - val_loss: 0.9102 - val_accuracy: 0.7949\n",
            "Epoch 72/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2772 - accuracy: 0.8626 - val_loss: 0.9085 - val_accuracy: 0.7949\n",
            "Epoch 73/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2795 - accuracy: 0.8650 - val_loss: 0.8303 - val_accuracy: 0.7885\n",
            "Epoch 74/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2591 - accuracy: 0.8712 - val_loss: 0.8524 - val_accuracy: 0.7949\n",
            "Epoch 75/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2857 - accuracy: 0.8443 - val_loss: 0.8971 - val_accuracy: 0.7949\n",
            "Epoch 76/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8258 - val_loss: 0.8940 - val_accuracy: 0.8013\n",
            "Epoch 77/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.3020 - accuracy: 0.8390 - val_loss: 0.8935 - val_accuracy: 0.7949\n",
            "Epoch 78/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2798 - accuracy: 0.8518 - val_loss: 0.8887 - val_accuracy: 0.8013\n",
            "Epoch 79/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3142 - accuracy: 0.8296 - val_loss: 0.8863 - val_accuracy: 0.8013\n",
            "Epoch 80/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2878 - accuracy: 0.8545 - val_loss: 0.8813 - val_accuracy: 0.8013\n",
            "Epoch 81/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2891 - accuracy: 0.8570 - val_loss: 0.8858 - val_accuracy: 0.8013\n",
            "Epoch 82/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2636 - accuracy: 0.8792 - val_loss: 0.8807 - val_accuracy: 0.8013\n",
            "Epoch 83/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2287 - accuracy: 0.8892 - val_loss: 0.8799 - val_accuracy: 0.7949\n",
            "Epoch 84/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.8875 - val_loss: 0.8749 - val_accuracy: 0.7949\n",
            "Epoch 85/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2224 - accuracy: 0.8882 - val_loss: 0.8711 - val_accuracy: 0.7949\n",
            "Epoch 86/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2142 - accuracy: 0.8848 - val_loss: 0.8654 - val_accuracy: 0.8013\n",
            "Epoch 87/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2436 - accuracy: 0.8783 - val_loss: 0.8616 - val_accuracy: 0.8077\n",
            "Epoch 88/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2747 - accuracy: 0.8475 - val_loss: 0.8581 - val_accuracy: 0.8141\n",
            "Epoch 89/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.8699 - val_loss: 0.7828 - val_accuracy: 0.8141\n",
            "Epoch 90/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2626 - accuracy: 0.8734 - val_loss: 0.7794 - val_accuracy: 0.8141\n",
            "Epoch 91/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2547 - accuracy: 0.8715 - val_loss: 0.8519 - val_accuracy: 0.8141\n",
            "Epoch 92/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2646 - accuracy: 0.8607 - val_loss: 0.8480 - val_accuracy: 0.8205\n",
            "Epoch 93/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2216 - accuracy: 0.8792 - val_loss: 0.8448 - val_accuracy: 0.8269\n",
            "Epoch 94/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2402 - accuracy: 0.8643 - val_loss: 0.8397 - val_accuracy: 0.8333\n",
            "Epoch 95/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2086 - accuracy: 0.8971 - val_loss: 0.8320 - val_accuracy: 0.8333\n",
            "Epoch 96/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2265 - accuracy: 0.8756 - val_loss: 0.8336 - val_accuracy: 0.8397\n",
            "Epoch 97/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.8641 - val_loss: 0.7639 - val_accuracy: 0.8462\n",
            "Epoch 98/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2215 - accuracy: 0.8819 - val_loss: 0.8317 - val_accuracy: 0.8526\n",
            "Epoch 99/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1993 - accuracy: 0.8908 - val_loss: 0.8286 - val_accuracy: 0.8590\n",
            "Epoch 100/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2749 - accuracy: 0.8435 - val_loss: 0.8224 - val_accuracy: 0.8526\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faded2fb910>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SErCpywSSbQe",
        "outputId": "ea184eb2-78b0-487b-c7e9-cbd9e63d71a8"
      },
      "source": [
        "# evaluate the model\n",
        "scores = model.evaluate(X, Y)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17/17 [==============================] - 0s 1ms/step - loss: 0.4053 - accuracy: 0.8665\n",
            "accuracy: 86.65%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MztEqdaSimI"
      },
      "source": [
        "# Iteration 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qO6drUmcSg7B",
        "outputId": "a54ced53-2bcb-4779-94e5-e481c9f47921"
      },
      "source": [
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=24, activation='relu'))\n",
        "model.add(Dense(8,activation='relu'))\n",
        "model.add(Dense(1,activation='relu'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, Y, validation_split=0.3, epochs=100, batch_size=15)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "25/25 [==============================] - 1s 12ms/step - loss: 4.0317 - accuracy: 0.4487 - val_loss: 2.5774 - val_accuracy: 0.5577\n",
            "Epoch 2/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 3.2247 - accuracy: 0.5371 - val_loss: 2.5547 - val_accuracy: 0.5705\n",
            "Epoch 3/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 2.9639 - accuracy: 0.5441 - val_loss: 2.4940 - val_accuracy: 0.5833\n",
            "Epoch 4/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 2.7666 - accuracy: 0.5384 - val_loss: 2.3451 - val_accuracy: 0.5897\n",
            "Epoch 5/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 2.1722 - accuracy: 0.5920 - val_loss: 2.2289 - val_accuracy: 0.6218\n",
            "Epoch 6/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 2.4539 - accuracy: 0.5900 - val_loss: 2.2155 - val_accuracy: 0.6218\n",
            "Epoch 7/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 2.0835 - accuracy: 0.6292 - val_loss: 2.1984 - val_accuracy: 0.6410\n",
            "Epoch 8/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 2.0569 - accuracy: 0.6486 - val_loss: 2.1141 - val_accuracy: 0.6410\n",
            "Epoch 9/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 1.6658 - accuracy: 0.7032 - val_loss: 2.0342 - val_accuracy: 0.6410\n",
            "Epoch 10/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 2.0927 - accuracy: 0.7005 - val_loss: 1.9667 - val_accuracy: 0.6346\n",
            "Epoch 11/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 2.1144 - accuracy: 0.6559 - val_loss: 1.9426 - val_accuracy: 0.6346\n",
            "Epoch 12/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 2.0948 - accuracy: 0.6988 - val_loss: 1.9327 - val_accuracy: 0.6346\n",
            "Epoch 13/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 1.7621 - accuracy: 0.6561 - val_loss: 1.9167 - val_accuracy: 0.6410\n",
            "Epoch 14/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 1.7608 - accuracy: 0.6976 - val_loss: 1.8372 - val_accuracy: 0.6410\n",
            "Epoch 15/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 1.4507 - accuracy: 0.7244 - val_loss: 1.8241 - val_accuracy: 0.6474\n",
            "Epoch 16/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 1.8700 - accuracy: 0.6964 - val_loss: 1.8347 - val_accuracy: 0.6410\n",
            "Epoch 17/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 1.7635 - accuracy: 0.7045 - val_loss: 1.8922 - val_accuracy: 0.6410\n",
            "Epoch 18/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 1.3962 - accuracy: 0.7447 - val_loss: 1.8329 - val_accuracy: 0.6282\n",
            "Epoch 19/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.8489 - accuracy: 0.7129 - val_loss: 1.4217 - val_accuracy: 0.6410\n",
            "Epoch 20/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.7852 - accuracy: 0.7082 - val_loss: 1.4278 - val_accuracy: 0.6474\n",
            "Epoch 21/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.6394 - accuracy: 0.7576 - val_loss: 1.3021 - val_accuracy: 0.6474\n",
            "Epoch 22/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.7769 - accuracy: 0.7678 - val_loss: 1.2087 - val_accuracy: 0.6474\n",
            "Epoch 23/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.7636 - val_loss: 1.1937 - val_accuracy: 0.6474\n",
            "Epoch 24/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7584 - val_loss: 1.1831 - val_accuracy: 0.6474\n",
            "Epoch 25/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6818 - accuracy: 0.7630 - val_loss: 1.1720 - val_accuracy: 0.6667\n",
            "Epoch 26/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5945 - accuracy: 0.8049 - val_loss: 1.1666 - val_accuracy: 0.6667\n",
            "Epoch 27/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6741 - accuracy: 0.7474 - val_loss: 1.1625 - val_accuracy: 0.6667\n",
            "Epoch 28/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6617 - accuracy: 0.7684 - val_loss: 1.1587 - val_accuracy: 0.6859\n",
            "Epoch 29/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.6259 - accuracy: 0.7929 - val_loss: 1.1553 - val_accuracy: 0.6859\n",
            "Epoch 30/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.6584 - accuracy: 0.7799 - val_loss: 1.1496 - val_accuracy: 0.6859\n",
            "Epoch 31/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.7966 - val_loss: 1.1451 - val_accuracy: 0.6923\n",
            "Epoch 32/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.6428 - accuracy: 0.7942 - val_loss: 1.1466 - val_accuracy: 0.6923\n",
            "Epoch 33/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.8174 - val_loss: 1.1440 - val_accuracy: 0.6923\n",
            "Epoch 34/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.8108 - val_loss: 1.1474 - val_accuracy: 0.6923\n",
            "Epoch 35/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.6609 - accuracy: 0.7585 - val_loss: 1.1461 - val_accuracy: 0.6987\n",
            "Epoch 36/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4903 - accuracy: 0.8297 - val_loss: 1.1398 - val_accuracy: 0.6987\n",
            "Epoch 37/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.8333 - val_loss: 1.1395 - val_accuracy: 0.7051\n",
            "Epoch 38/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.6832 - accuracy: 0.7806 - val_loss: 1.1403 - val_accuracy: 0.6987\n",
            "Epoch 39/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6158 - accuracy: 0.8110 - val_loss: 1.1402 - val_accuracy: 0.6987\n",
            "Epoch 40/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.8021 - val_loss: 1.1394 - val_accuracy: 0.7051\n",
            "Epoch 41/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6276 - accuracy: 0.7772 - val_loss: 1.1368 - val_accuracy: 0.7051\n",
            "Epoch 42/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5466 - accuracy: 0.7988 - val_loss: 1.1380 - val_accuracy: 0.7051\n",
            "Epoch 43/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.7916 - val_loss: 1.1391 - val_accuracy: 0.7051\n",
            "Epoch 44/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6122 - accuracy: 0.8063 - val_loss: 1.1449 - val_accuracy: 0.7051\n",
            "Epoch 45/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5724 - accuracy: 0.8076 - val_loss: 1.1407 - val_accuracy: 0.7051\n",
            "Epoch 46/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5904 - accuracy: 0.7848 - val_loss: 1.1405 - val_accuracy: 0.7179\n",
            "Epoch 47/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.8233 - val_loss: 1.1437 - val_accuracy: 0.7115\n",
            "Epoch 48/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.8285 - val_loss: 1.1425 - val_accuracy: 0.7115\n",
            "Epoch 49/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5873 - accuracy: 0.8126 - val_loss: 1.1413 - val_accuracy: 0.7115\n",
            "Epoch 50/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5414 - accuracy: 0.7944 - val_loss: 1.1413 - val_accuracy: 0.7115\n",
            "Epoch 51/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.8101 - val_loss: 1.1445 - val_accuracy: 0.7179\n",
            "Epoch 52/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4681 - accuracy: 0.8247 - val_loss: 1.1640 - val_accuracy: 0.7179\n",
            "Epoch 53/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.8388 - val_loss: 1.1614 - val_accuracy: 0.7179\n",
            "Epoch 54/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7993 - val_loss: 1.1476 - val_accuracy: 0.7115\n",
            "Epoch 55/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5341 - accuracy: 0.8099 - val_loss: 1.1350 - val_accuracy: 0.7115\n",
            "Epoch 56/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.8431 - val_loss: 1.1301 - val_accuracy: 0.7115\n",
            "Epoch 57/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5009 - accuracy: 0.8132 - val_loss: 1.1289 - val_accuracy: 0.7179\n",
            "Epoch 58/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.8447 - val_loss: 1.1298 - val_accuracy: 0.7115\n",
            "Epoch 59/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.8299 - val_loss: 1.1260 - val_accuracy: 0.7179\n",
            "Epoch 60/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.8249 - val_loss: 1.1264 - val_accuracy: 0.7115\n",
            "Epoch 61/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.8279 - val_loss: 1.1231 - val_accuracy: 0.7179\n",
            "Epoch 62/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4987 - accuracy: 0.7865 - val_loss: 1.1246 - val_accuracy: 0.7244\n",
            "Epoch 63/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5599 - accuracy: 0.7838 - val_loss: 1.1228 - val_accuracy: 0.7179\n",
            "Epoch 64/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4056 - accuracy: 0.8083 - val_loss: 1.1248 - val_accuracy: 0.7179\n",
            "Epoch 65/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4946 - accuracy: 0.8033 - val_loss: 1.1240 - val_accuracy: 0.7179\n",
            "Epoch 66/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.8316 - val_loss: 1.1243 - val_accuracy: 0.7244\n",
            "Epoch 67/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.8066 - val_loss: 1.1282 - val_accuracy: 0.7244\n",
            "Epoch 68/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.8365 - val_loss: 1.1294 - val_accuracy: 0.7308\n",
            "Epoch 69/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5492 - accuracy: 0.8047 - val_loss: 1.0737 - val_accuracy: 0.7244\n",
            "Epoch 70/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.8414 - val_loss: 1.0648 - val_accuracy: 0.7179\n",
            "Epoch 71/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4059 - accuracy: 0.8232 - val_loss: 1.0634 - val_accuracy: 0.7179\n",
            "Epoch 72/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.8362 - val_loss: 1.1338 - val_accuracy: 0.7179\n",
            "Epoch 73/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.8350 - val_loss: 1.0564 - val_accuracy: 0.7179\n",
            "Epoch 74/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.8258 - val_loss: 1.0481 - val_accuracy: 0.7179\n",
            "Epoch 75/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5771 - accuracy: 0.8430 - val_loss: 1.0393 - val_accuracy: 0.7179\n",
            "Epoch 76/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.8221 - val_loss: 1.0314 - val_accuracy: 0.7179\n",
            "Epoch 77/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.7971 - val_loss: 1.0369 - val_accuracy: 0.7179\n",
            "Epoch 78/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5653 - accuracy: 0.8107 - val_loss: 1.0330 - val_accuracy: 0.7244\n",
            "Epoch 79/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.8302 - val_loss: 1.0262 - val_accuracy: 0.7179\n",
            "Epoch 80/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5328 - accuracy: 0.8529 - val_loss: 1.0258 - val_accuracy: 0.7179\n",
            "Epoch 81/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8519 - val_loss: 1.0295 - val_accuracy: 0.7179\n",
            "Epoch 82/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.8130 - val_loss: 1.0338 - val_accuracy: 0.7179\n",
            "Epoch 83/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.8381 - val_loss: 1.0966 - val_accuracy: 0.7179\n",
            "Epoch 84/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6175 - accuracy: 0.8194 - val_loss: 1.0938 - val_accuracy: 0.7115\n",
            "Epoch 85/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.3765 - accuracy: 0.8349 - val_loss: 1.0875 - val_accuracy: 0.7179\n",
            "Epoch 86/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4042 - accuracy: 0.8754 - val_loss: 1.0858 - val_accuracy: 0.7244\n",
            "Epoch 87/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.8402 - val_loss: 1.0832 - val_accuracy: 0.7244\n",
            "Epoch 88/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.8458 - val_loss: 1.0826 - val_accuracy: 0.7244\n",
            "Epoch 89/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.8607 - val_loss: 1.0812 - val_accuracy: 0.7244\n",
            "Epoch 90/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5670 - accuracy: 0.8526 - val_loss: 1.0788 - val_accuracy: 0.7308\n",
            "Epoch 91/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.8433 - val_loss: 0.9959 - val_accuracy: 0.7244\n",
            "Epoch 92/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.8829 - val_loss: 1.0058 - val_accuracy: 0.7244\n",
            "Epoch 93/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.8607 - val_loss: 1.0711 - val_accuracy: 0.7244\n",
            "Epoch 94/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.3990 - accuracy: 0.8871 - val_loss: 1.0697 - val_accuracy: 0.7308\n",
            "Epoch 95/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4064 - accuracy: 0.8453 - val_loss: 1.0734 - val_accuracy: 0.7244\n",
            "Epoch 96/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.8469 - val_loss: 1.0719 - val_accuracy: 0.7179\n",
            "Epoch 97/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.8404 - val_loss: 1.0662 - val_accuracy: 0.7115\n",
            "Epoch 98/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8822 - val_loss: 1.0686 - val_accuracy: 0.7179\n",
            "Epoch 99/100\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3608 - accuracy: 0.8725 - val_loss: 1.0662 - val_accuracy: 0.7244\n",
            "Epoch 100/100\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.8745 - val_loss: 1.0669 - val_accuracy: 0.7244\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faded2e4b90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGLYtH5hSmqd",
        "outputId": "fc7518d6-68f1-4602-f038-f1ea863e7677"
      },
      "source": [
        "# evaluate the model\n",
        "scores = model.evaluate(X, Y)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17/17 [==============================] - 0s 1ms/step - loss: 0.6035 - accuracy: 0.8298\n",
            "accuracy: 82.98%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuc9ebHES0Gi"
      },
      "source": [
        "#Iteration 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAjhdIYwSxtd",
        "outputId": "8c11463e-9ab3-48eb-8315-f5cdbf45f482"
      },
      "source": [
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=24, activation='relu'))\n",
        "model.add(Dense(8,activation='relu'))\n",
        "model.add(Dense(1,activation='relu'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, Y, validation_split=0.3, epochs=150, batch_size=10)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "37/37 [==============================] - 1s 8ms/step - loss: 2.3664 - accuracy: 0.7532 - val_loss: 3.5491 - val_accuracy: 0.6795\n",
            "Epoch 2/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 2.5151 - accuracy: 0.7513 - val_loss: 3.5545 - val_accuracy: 0.7051\n",
            "Epoch 3/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 2.4018 - accuracy: 0.7863 - val_loss: 3.7010 - val_accuracy: 0.7051\n",
            "Epoch 4/150\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 2.5942 - accuracy: 0.7615 - val_loss: 3.3621 - val_accuracy: 0.6923\n",
            "Epoch 5/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 2.5568 - accuracy: 0.7625 - val_loss: 3.4517 - val_accuracy: 0.6859\n",
            "Epoch 6/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.9543 - accuracy: 0.8279 - val_loss: 3.4339 - val_accuracy: 0.6987\n",
            "Epoch 7/150\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.9182 - accuracy: 0.8162 - val_loss: 3.4462 - val_accuracy: 0.6923\n",
            "Epoch 8/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.8396 - accuracy: 0.8130 - val_loss: 3.5137 - val_accuracy: 0.6923\n",
            "Epoch 9/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.6846 - accuracy: 0.8200 - val_loss: 3.4370 - val_accuracy: 0.7051\n",
            "Epoch 10/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 2.5776 - accuracy: 0.7843 - val_loss: 3.4329 - val_accuracy: 0.6987\n",
            "Epoch 11/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.6675 - accuracy: 0.8287 - val_loss: 3.4353 - val_accuracy: 0.7115\n",
            "Epoch 12/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 2.3328 - accuracy: 0.8024 - val_loss: 3.4468 - val_accuracy: 0.7115\n",
            "Epoch 13/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 2.3050 - accuracy: 0.8035 - val_loss: 3.4464 - val_accuracy: 0.7115\n",
            "Epoch 14/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 2.0874 - accuracy: 0.8056 - val_loss: 3.3833 - val_accuracy: 0.7115\n",
            "Epoch 15/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.8231 - accuracy: 0.8349 - val_loss: 3.4457 - val_accuracy: 0.7115\n",
            "Epoch 16/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 2.0557 - accuracy: 0.8001 - val_loss: 3.4291 - val_accuracy: 0.7179\n",
            "Epoch 17/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.3764 - accuracy: 0.8695 - val_loss: 3.3662 - val_accuracy: 0.7115\n",
            "Epoch 18/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.6290 - accuracy: 0.8318 - val_loss: 3.4357 - val_accuracy: 0.7115\n",
            "Epoch 19/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 2.3870 - accuracy: 0.8113 - val_loss: 3.4374 - val_accuracy: 0.7115\n",
            "Epoch 20/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.9551 - accuracy: 0.8255 - val_loss: 3.4439 - val_accuracy: 0.7115\n",
            "Epoch 21/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.8000 - accuracy: 0.8318 - val_loss: 3.3635 - val_accuracy: 0.7179\n",
            "Epoch 22/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.9662 - accuracy: 0.8186 - val_loss: 3.3497 - val_accuracy: 0.7179\n",
            "Epoch 23/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.5483 - accuracy: 0.8563 - val_loss: 3.3520 - val_accuracy: 0.7179\n",
            "Epoch 24/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.4714 - accuracy: 0.8434 - val_loss: 3.3739 - val_accuracy: 0.7179\n",
            "Epoch 25/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 2.0056 - accuracy: 0.7925 - val_loss: 3.4718 - val_accuracy: 0.7179\n",
            "Epoch 26/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.9492 - accuracy: 0.8302 - val_loss: 3.4409 - val_accuracy: 0.7179\n",
            "Epoch 27/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.9552 - accuracy: 0.8223 - val_loss: 3.5143 - val_accuracy: 0.7179\n",
            "Epoch 28/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.4514 - accuracy: 0.8525 - val_loss: 3.0244 - val_accuracy: 0.6987\n",
            "Epoch 29/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.8296 - accuracy: 0.7895 - val_loss: 3.1779 - val_accuracy: 0.6923\n",
            "Epoch 30/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.2659 - accuracy: 0.8351 - val_loss: 3.1937 - val_accuracy: 0.6859\n",
            "Epoch 31/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.1162 - accuracy: 0.8407 - val_loss: 2.9155 - val_accuracy: 0.6795\n",
            "Epoch 32/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.4836 - accuracy: 0.8186 - val_loss: 2.6720 - val_accuracy: 0.6923\n",
            "Epoch 33/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.1125 - accuracy: 0.8388 - val_loss: 2.7924 - val_accuracy: 0.6923\n",
            "Epoch 34/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.1437 - accuracy: 0.8383 - val_loss: 2.8877 - val_accuracy: 0.6923\n",
            "Epoch 35/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.2058 - accuracy: 0.8517 - val_loss: 3.0576 - val_accuracy: 0.6859\n",
            "Epoch 36/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.0806 - accuracy: 0.8599 - val_loss: 2.9885 - val_accuracy: 0.6987\n",
            "Epoch 37/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.1611 - accuracy: 0.8399 - val_loss: 3.1762 - val_accuracy: 0.6923\n",
            "Epoch 38/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.1260 - accuracy: 0.8706 - val_loss: 2.9672 - val_accuracy: 0.6923\n",
            "Epoch 39/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.1517 - accuracy: 0.8300 - val_loss: 3.0469 - val_accuracy: 0.6923\n",
            "Epoch 40/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.0970 - accuracy: 0.8511 - val_loss: 3.1110 - val_accuracy: 0.6923\n",
            "Epoch 41/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.0119 - accuracy: 0.8328 - val_loss: 3.0491 - val_accuracy: 0.6859\n",
            "Epoch 42/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.8571 - accuracy: 0.8508 - val_loss: 3.0483 - val_accuracy: 0.6859\n",
            "Epoch 43/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.0093 - accuracy: 0.8578 - val_loss: 2.9645 - val_accuracy: 0.6923\n",
            "Epoch 44/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.0662 - accuracy: 0.8481 - val_loss: 2.9590 - val_accuracy: 0.6859\n",
            "Epoch 45/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.9587 - accuracy: 0.8532 - val_loss: 2.9479 - val_accuracy: 0.6923\n",
            "Epoch 46/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.0189 - accuracy: 0.8657 - val_loss: 2.9452 - val_accuracy: 0.6923\n",
            "Epoch 47/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.1157 - accuracy: 0.8579 - val_loss: 2.9445 - val_accuracy: 0.6987\n",
            "Epoch 48/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.9472 - accuracy: 0.8573 - val_loss: 2.9387 - val_accuracy: 0.7051\n",
            "Epoch 49/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.6179 - accuracy: 0.8143 - val_loss: 2.9341 - val_accuracy: 0.7051\n",
            "Epoch 50/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.5315 - accuracy: 0.8041 - val_loss: 2.9318 - val_accuracy: 0.7051\n",
            "Epoch 51/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.1862 - accuracy: 0.8433 - val_loss: 2.9316 - val_accuracy: 0.7051\n",
            "Epoch 52/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.1628 - accuracy: 0.8588 - val_loss: 2.9315 - val_accuracy: 0.7051\n",
            "Epoch 53/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.0942 - accuracy: 0.8570 - val_loss: 2.9302 - val_accuracy: 0.7051\n",
            "Epoch 54/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.1762 - accuracy: 0.8576 - val_loss: 2.9237 - val_accuracy: 0.7051\n",
            "Epoch 55/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.1196 - accuracy: 0.8518 - val_loss: 2.9258 - val_accuracy: 0.7051\n",
            "Epoch 56/150\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.1162 - accuracy: 0.8580 - val_loss: 2.9317 - val_accuracy: 0.7051\n",
            "Epoch 57/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.1598 - accuracy: 0.8531 - val_loss: 2.9328 - val_accuracy: 0.7051\n",
            "Epoch 58/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.0101 - accuracy: 0.8423 - val_loss: 2.9302 - val_accuracy: 0.7051\n",
            "Epoch 59/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.9198 - accuracy: 0.8522 - val_loss: 2.9309 - val_accuracy: 0.6987\n",
            "Epoch 60/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.2035 - accuracy: 0.8496 - val_loss: 2.9404 - val_accuracy: 0.7051\n",
            "Epoch 61/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.3997 - accuracy: 0.8502 - val_loss: 2.9310 - val_accuracy: 0.6987\n",
            "Epoch 62/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.3436 - accuracy: 0.8582 - val_loss: 2.9378 - val_accuracy: 0.7115\n",
            "Epoch 63/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.3008 - accuracy: 0.8464 - val_loss: 2.9335 - val_accuracy: 0.7051\n",
            "Epoch 64/150\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9411 - accuracy: 0.8783 - val_loss: 2.9321 - val_accuracy: 0.6987\n",
            "Epoch 65/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.3321 - accuracy: 0.8354 - val_loss: 2.9577 - val_accuracy: 0.6987\n",
            "Epoch 66/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.1979 - accuracy: 0.8679 - val_loss: 2.9463 - val_accuracy: 0.6987\n",
            "Epoch 67/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.0043 - accuracy: 0.8880 - val_loss: 3.0196 - val_accuracy: 0.7051\n",
            "Epoch 68/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.2083 - accuracy: 0.8491 - val_loss: 2.9585 - val_accuracy: 0.6987\n",
            "Epoch 69/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.9539 - accuracy: 0.8819 - val_loss: 3.0138 - val_accuracy: 0.6987\n",
            "Epoch 70/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.0756 - accuracy: 0.8718 - val_loss: 3.0110 - val_accuracy: 0.7051\n",
            "Epoch 71/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.2462 - accuracy: 0.8568 - val_loss: 3.0780 - val_accuracy: 0.7051\n",
            "Epoch 72/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.1372 - accuracy: 0.8628 - val_loss: 3.0763 - val_accuracy: 0.7051\n",
            "Epoch 73/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.9655 - accuracy: 0.8781 - val_loss: 3.0305 - val_accuracy: 0.7051\n",
            "Epoch 74/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.0482 - accuracy: 0.8773 - val_loss: 3.0846 - val_accuracy: 0.7051\n",
            "Epoch 75/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.0919 - accuracy: 0.8895 - val_loss: 2.9285 - val_accuracy: 0.7051\n",
            "Epoch 76/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.0260 - accuracy: 0.8875 - val_loss: 2.9231 - val_accuracy: 0.7051\n",
            "Epoch 77/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.9620 - accuracy: 0.8946 - val_loss: 2.9196 - val_accuracy: 0.7051\n",
            "Epoch 78/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.2453 - accuracy: 0.8504 - val_loss: 3.0004 - val_accuracy: 0.7115\n",
            "Epoch 79/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.2922 - accuracy: 0.8454 - val_loss: 2.9101 - val_accuracy: 0.7115\n",
            "Epoch 80/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.9751 - accuracy: 0.8964 - val_loss: 2.9779 - val_accuracy: 0.7115\n",
            "Epoch 81/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.0278 - accuracy: 0.8984 - val_loss: 2.9068 - val_accuracy: 0.7115\n",
            "Epoch 82/150\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.4248 - accuracy: 0.8658 - val_loss: 2.9055 - val_accuracy: 0.7051\n",
            "Epoch 83/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.2840 - accuracy: 0.8677 - val_loss: 2.8070 - val_accuracy: 0.7115\n",
            "Epoch 84/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.0737 - accuracy: 0.8643 - val_loss: 2.8035 - val_accuracy: 0.7179\n",
            "Epoch 85/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.8631 - accuracy: 0.8773 - val_loss: 2.8073 - val_accuracy: 0.7115\n",
            "Epoch 86/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.1090 - accuracy: 0.8794 - val_loss: 2.8046 - val_accuracy: 0.7115\n",
            "Epoch 87/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.8476 - accuracy: 0.9108 - val_loss: 2.8074 - val_accuracy: 0.6987\n",
            "Epoch 88/150\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1.5880 - accuracy: 0.8557 - val_loss: 2.8048 - val_accuracy: 0.6987\n",
            "Epoch 89/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.0213 - accuracy: 0.9097 - val_loss: 2.8022 - val_accuracy: 0.6987\n",
            "Epoch 90/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.1087 - accuracy: 0.8882 - val_loss: 2.7943 - val_accuracy: 0.6987\n",
            "Epoch 91/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.7816 - accuracy: 0.9036 - val_loss: 2.7957 - val_accuracy: 0.6987\n",
            "Epoch 92/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.0894 - accuracy: 0.8875 - val_loss: 2.7882 - val_accuracy: 0.7051\n",
            "Epoch 93/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.2036 - accuracy: 0.8844 - val_loss: 2.7884 - val_accuracy: 0.7051\n",
            "Epoch 94/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.2868 - accuracy: 0.8645 - val_loss: 2.7828 - val_accuracy: 0.7051\n",
            "Epoch 95/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.1915 - accuracy: 0.8872 - val_loss: 2.7256 - val_accuracy: 0.6987\n",
            "Epoch 96/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.2378 - accuracy: 0.8853 - val_loss: 2.7786 - val_accuracy: 0.7115\n",
            "Epoch 97/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.8713 - accuracy: 0.9076 - val_loss: 2.7083 - val_accuracy: 0.7115\n",
            "Epoch 98/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.9929 - accuracy: 0.8994 - val_loss: 2.7114 - val_accuracy: 0.7115\n",
            "Epoch 99/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.1599 - accuracy: 0.8709 - val_loss: 2.7727 - val_accuracy: 0.7115\n",
            "Epoch 100/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.9884 - accuracy: 0.9006 - val_loss: 2.7746 - val_accuracy: 0.7179\n",
            "Epoch 101/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.2161 - accuracy: 0.8666 - val_loss: 2.7657 - val_accuracy: 0.7179\n",
            "Epoch 102/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.1247 - accuracy: 0.8805 - val_loss: 2.7685 - val_accuracy: 0.7179\n",
            "Epoch 103/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.4798 - accuracy: 0.8587 - val_loss: 2.7682 - val_accuracy: 0.7244\n",
            "Epoch 104/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.0960 - accuracy: 0.9134 - val_loss: 2.7710 - val_accuracy: 0.7244\n",
            "Epoch 105/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.9650 - accuracy: 0.9020 - val_loss: 2.7657 - val_accuracy: 0.7244\n",
            "Epoch 106/150\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9200 - accuracy: 0.8913 - val_loss: 2.7616 - val_accuracy: 0.7179\n",
            "Epoch 107/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.1218 - accuracy: 0.9043 - val_loss: 2.6887 - val_accuracy: 0.7244\n",
            "Epoch 108/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.9305 - accuracy: 0.9031 - val_loss: 2.6882 - val_accuracy: 0.7244\n",
            "Epoch 109/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.6148 - accuracy: 0.8666 - val_loss: 2.6028 - val_accuracy: 0.7179\n",
            "Epoch 110/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.9617 - accuracy: 0.9113 - val_loss: 2.7870 - val_accuracy: 0.7372\n",
            "Epoch 111/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.7810 - accuracy: 0.9374 - val_loss: 2.6764 - val_accuracy: 0.7308\n",
            "Epoch 112/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.9703 - accuracy: 0.9165 - val_loss: 2.6742 - val_accuracy: 0.7051\n",
            "Epoch 113/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.1839 - accuracy: 0.8839 - val_loss: 2.6716 - val_accuracy: 0.7115\n",
            "Epoch 114/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.8823 - accuracy: 0.9137 - val_loss: 2.6608 - val_accuracy: 0.7115\n",
            "Epoch 115/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.9437 - accuracy: 0.9100 - val_loss: 2.6626 - val_accuracy: 0.7179\n",
            "Epoch 116/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.0996 - accuracy: 0.8928 - val_loss: 2.6559 - val_accuracy: 0.7179\n",
            "Epoch 117/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.8383 - accuracy: 0.9203 - val_loss: 2.6674 - val_accuracy: 0.7244\n",
            "Epoch 118/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.0269 - accuracy: 0.9157 - val_loss: 2.5730 - val_accuracy: 0.7244\n",
            "Epoch 119/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.3109 - accuracy: 0.8738 - val_loss: 2.5880 - val_accuracy: 0.7308\n",
            "Epoch 120/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.0772 - accuracy: 0.8909 - val_loss: 2.6557 - val_accuracy: 0.7308\n",
            "Epoch 121/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.3009 - accuracy: 0.8751 - val_loss: 2.5710 - val_accuracy: 0.7244\n",
            "Epoch 122/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.6344 - accuracy: 0.9204 - val_loss: 2.5780 - val_accuracy: 0.7244\n",
            "Epoch 123/150\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.7868 - accuracy: 0.9032 - val_loss: 2.6531 - val_accuracy: 0.7244\n",
            "Epoch 124/150\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.8893 - accuracy: 0.8849 - val_loss: 2.3688 - val_accuracy: 0.7115\n",
            "Epoch 125/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.7846 - accuracy: 0.8863 - val_loss: 2.4506 - val_accuracy: 0.7244\n",
            "Epoch 126/150\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5351 - accuracy: 0.9017 - val_loss: 2.4470 - val_accuracy: 0.7179\n",
            "Epoch 127/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.6871 - accuracy: 0.9184 - val_loss: 2.4309 - val_accuracy: 0.7179\n",
            "Epoch 128/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.7730 - accuracy: 0.9082 - val_loss: 2.5059 - val_accuracy: 0.7308\n",
            "Epoch 129/150\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.9017 - val_loss: 2.4372 - val_accuracy: 0.7372\n",
            "Epoch 130/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.5703 - accuracy: 0.9254 - val_loss: 2.5872 - val_accuracy: 0.7308\n",
            "Epoch 131/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.9162 - val_loss: 2.5787 - val_accuracy: 0.7372\n",
            "Epoch 132/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.9397 - val_loss: 2.5933 - val_accuracy: 0.7244\n",
            "Epoch 133/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.9405 - val_loss: 2.6147 - val_accuracy: 0.7372\n",
            "Epoch 134/150\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.7477 - accuracy: 0.9207 - val_loss: 2.7504 - val_accuracy: 0.7308\n",
            "Epoch 135/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.8012 - accuracy: 0.9046 - val_loss: 2.7682 - val_accuracy: 0.7308\n",
            "Epoch 136/150\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4954 - accuracy: 0.9478 - val_loss: 2.7611 - val_accuracy: 0.7308\n",
            "Epoch 137/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.7035 - accuracy: 0.9198 - val_loss: 2.8381 - val_accuracy: 0.7436\n",
            "Epoch 138/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.6240 - accuracy: 0.9159 - val_loss: 2.8419 - val_accuracy: 0.7372\n",
            "Epoch 139/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.6259 - accuracy: 0.9239 - val_loss: 2.8364 - val_accuracy: 0.7244\n",
            "Epoch 140/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.6596 - accuracy: 0.9186 - val_loss: 2.9137 - val_accuracy: 0.7244\n",
            "Epoch 141/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.9390 - val_loss: 2.9159 - val_accuracy: 0.7308\n",
            "Epoch 142/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.9439 - val_loss: 2.9189 - val_accuracy: 0.7308\n",
            "Epoch 143/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.7307 - accuracy: 0.9088 - val_loss: 2.8477 - val_accuracy: 0.7179\n",
            "Epoch 144/150\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.7890 - accuracy: 0.9281 - val_loss: 2.9151 - val_accuracy: 0.7179\n",
            "Epoch 145/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.5905 - accuracy: 0.9278 - val_loss: 2.9111 - val_accuracy: 0.7179\n",
            "Epoch 146/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.9435 - val_loss: 2.9157 - val_accuracy: 0.7372\n",
            "Epoch 147/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.6058 - accuracy: 0.9402 - val_loss: 2.9158 - val_accuracy: 0.7179\n",
            "Epoch 148/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.8899 - accuracy: 0.9212 - val_loss: 2.9238 - val_accuracy: 0.7308\n",
            "Epoch 149/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.9417 - val_loss: 2.9149 - val_accuracy: 0.7372\n",
            "Epoch 150/150\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.9589 - val_loss: 2.9211 - val_accuracy: 0.7308\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faded13ffd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXg0ygPoS3tj",
        "outputId": "d88194c3-3ca9-4fc4-d8af-ea0a87a18ef1"
      },
      "source": [
        "# evaluate the model\n",
        "scores = model.evaluate(X, Y)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17/17 [==============================] - 0s 1ms/step - loss: 1.3439 - accuracy: 0.8723\n",
            "accuracy: 87.23%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N596Ij44TBql"
      },
      "source": [
        "# Out of all the 4 Iterations we are getting best accuracy with Iteration 1 - 94.78%. So we can go ahead with those combinations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Sglq69jS_o8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}